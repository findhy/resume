<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Findhy">
  <meta name="copyright" content="© copyright 1998-2005 by Findhy">
  <title>Findhy's Resume</title>
  <style type="text/css">
   h1 { margin: 0.1em 0 0.25em 0; }
   h2 { margin-top: 1.25em; margin-bottom: 0.15em; }
   dt { font-weight: bold; margin-top: 0.5em; }
   th { text-align: left; padding-top: 1em; }
   body { margin: 0 1em 1em; border-bottom: solid thin; }
  </style>
  <script type="text/javascript">
  </script>
 </head>
 <body youdao="bind">
  <h1>孙伟(Findhy)</h1>
  <address><a href="mailto:findhyg@gmail.com">findhyg@gmail.com</a></address>
  <address><a href="#">tel:18601133918</a></address>
  <address><a href="http://blog.findhy.com/resume/" target="new">http://blog.findhy.com/resume/</a></address>
  <p>
  一直从事数据开发相关工作，从Oracle的存储过程到Hadoop平台的MapReduce，完成了RDBMS到NoSQL的转移，我的职业目标是通过最简单的方式来解开大数据的面纱，用最符合业务的语言来呈现数据中的规律，完成数据的价值转换，也是从事数据工作者的价值体现
  </p>
  <h2>个人介绍</h2>
  <p><strong>概述:</strong>
  作为一名合格的工程师，能快速学习一门新的语言或者框架，能快速适应新的团队和业务环境，也能够带领团队或与他人协作完成任务
  </p>
  <dl>
   <dt>编程语言</dt>
   <dd>Java、Python、Shell、SQL、JavaScript：这几个是在工作中都很熟悉的，可以达到马上上手完成一项任务的水平</dd>
   <dt>平台或框架</dt>
   <dd>Hadoop生态：了解HDFS与MapReduce原理，看过其中BloomFilter部分的源码，并提取用于业务使用。Hive、Sqoop、HBase、Kafka都有实际项目使用经验，对Storm、Titan、Mahout有过实际研究，可视化框架熟悉D3.js、Echars、Highcharts</dd>
   <dd>Oracle：比较擅长SQL优化和分析，有OCP认证</dd>
   <dd>Lucene：了解TF-IDF算法，有过实际项目经验，主要用于移动APP内搜索</dd>
   <dd>Redis：作为缓存来使用，还有就是作为消息队列来使用，通过blpop阻塞读取队列来实现消息的传递</dd>
   <dd>其它熟练技能：AngularJS、Node.js、Git、Maven、Spring</dd>
   <dt>其它</dt>
   <dd>总结和反思是成长的必经之路，平时会有记录博客的习惯：<a href="http://blog.findhy.com/" target="new">http://blog.findhy.com</a></dd>
   <dd>沟通能力是一个工程师必备的技能，个人比较擅长将复杂的业务问题描述并梳理清楚</dd>
   <dd>读书越多就越觉得自己知识浅薄，常有拖延，贵在坚持：<a href="http://book.douban.com/people/75301035/" target="new">http://book.douban.com/people/75301035</a></dd>
   <dd>知乎看得多写的少：<a href="http://www.zhihu.com/people/findhy" target="new">http://www.zhihu.com/people/findhy</a></dd>
   <dd>偶尔去墙外练练腿脚：<a href="https://twitter.com/sunwei553722769" target="new">https://twitter.com/sunwei553722769</a></dd>
  </dl>  
  <h2>工作经历</h2>
  <table>
   <tbody>
    <tr>
     <th> 搜狐畅游网络技术有限公司 </th>
     <th> Hadoop工程师 </th>
     <th> 2014.4-至今 </th>
    </tr>
    <tr>
     <td colspan="3">
      <ul>
       <li>
        <p>主导了移动广告平台-数据平台的搭建，从数据的收集到数据清洗再到数据可视化，通过对业务的理解，从移动广告的生命周期构建出一条数据运营轨迹，从广告的投放到广告激活到收费，通过数据呈现出各项业务指标提供给业务人员或者商务人员决策使用，整个平台的用户量在500万左右，每天产生的数据量大约150GB</p>
       </li>
	   <li>
        <p>整个数据平台是基于Hadoop生态系统搭建，使用亚马逊提供的EMR，版本是Hadoop2.2，数据的采集部分前期使用Python+Shell自己开发的形式，主要是由于前期业务产生的日志为文件形式，后期日志收集转移到Kafak上，主要是考虑到Kafak的效率和分布式，底层HDFS数据的存储采取的是亚马逊提供的S3存储，而没有采用本地磁盘，主要考虑的是成本还有S3提供的高可用性，数据的离线分析用Hive来完成，通过YARN的资源管理平台来管理，任务的分发的管理采用自己开发的平台，Hive最大的优点是能够快速响应业务的需要，完成一项数据分析的需求，而且如果是定期的需求，我们会将HQL固定到定时器中，每天晚上跑，再将数据导入到Mysql中，前端通过百度的Echars展现</p>
		<p>在线部分是采用HBase，用HBase来完成数据的清洗（结合MapReduce），和提供数据的线上实时查询，HBase通过RowKey查询的效率在毫秒级，而且不会随着数据量加大而且降低性能，但是在设计HBase结构的时候有两点需要考虑，一个是RowKey的设计，一个是Region的预分配，RowKey的设计应该考虑到后期的业务查询需求，满足最频繁的查询，因为HBase只能进行三种查询，RowKey、RowKey范围、全表扫描，通过RowKey或者RowKey范围是常用的查询方式；HBase表默认就一个Region，当达到一定条件会进行分裂，但是这样最大的坏处就是所有的数据插入的负载都在一台机器上，达不到我们期望的分布式的效果，而且默认的分裂结果不一定符合我们数据的规律，比如经常查询的数据放在同一个region中，所以这个时候最好在创建表的时候就指定Region的个数，一般而言Region的个数与RegionServer的个数相当；最后HBase建表尽量采用snappy压缩，这样可以提高写入的效率和减少存储空间</p>
       </li>
	   <li>
        <p>参与开发广告投放系统搜索模块，采用Lucene框架，对广告描述、广告名称和广告标签进行标准StandardAnalyzer分词，再通过前端app传过来的关键词找到对应的广告，会根据每个广告的匹配程度得到分数，再结合CTR计算部分，得到收益最大的广告返回给客户端</p>
       </li>
	   <li>
        <p>开发广告投放系统安装列表过滤模块，业务要求将用户已经安装的APP广告过滤掉，用户量在500万，而每个用户安装的APP在50个左右，如果全部放在缓存，需要很大的内存空间，最后考虑到这样的匹配并非严格的要求是100%准确，所以后来采用了Bloom Filter算法，算法的实现部分是参考Hadoop源码的实现</p>
       </li>
       <li>
        <p>在此期间也对Storm、Titan、Mahout、Node.js都进行了预研，由于业务的推进问题，都没有投入到实际项目中去，但对个人的提高还是有一些帮助的</p>
       </li>
      </ul>
     </td>
    </tr>
   </tbody>
   <tbody>
    <tr>
     <th> 中科软科技股份有限公司 </th>
     <th> ETL开发工程师 </th>
     <th> 2010.7-2014.3 </th>
    </tr>
    <tr>
     <td colspan="3">
      <ul>
       <li>
        <p>完成人保Hadoop数据仓库平台搭建，与传统数据仓库平台整合。该项目是中国人寿保险公司基于Hadoop生态系统搭建数据仓库平台，首先将数据从Oracle数据库中通过Sqoop导入到HDFS中，再结合Hive工具处理数据，最后将数据再导回到Oracle数据库中，供前端报表工具来调用</p>
       </li>
	   <li>
        <p>参与FESCO运营管理系统数据仓库ETL开发工作，完成对数据的提取和转换，主要使用的是Oracle的存储过程，对SQL优化还有Oracle的执行计划分析有一些心得，还有帮助财务部门和业务部门开发相应的业务报表，当时采用的商业收费的皕杰报表</p>
       </li>
	   <li>
        <p>参与FESCO运营管理系统架构搭建，于Oracle11G RAC + Webshpere8.5集群 + F5负载均衡 + Struts2 + Spring + Hibernate + Maven完成生产环境部署，该项目是基于人力资源行业领头公司-北京人力资源有限公司的核心运营管理系统，目标是实现公司内部的业务流程化、办公自动化和数据智能化，以及多个业务系统之间的整合</p>
       </li>
       <li>
        <p>参与FESCO外呼管理系统开发，该系统主要用来给呼叫中心Call Center进行呼叫任务管理，主要功能有呼叫任务接受、呼叫任务分配和处理以及结果反馈等。其中任务接受和反馈都需要和其它业务子系统进行交互，交互方式是通过Webservice调用，服务端Webservice基于CXF搭建，并使用SOAPUI进行测试</p>
       </li>
       <li>
        <p>参与北京市园林绿化局生态管理系统开发，该项目是北京市园林绿化局对北京市各个区县的绿化情况进行统计，通过FusionCharts展现出图形报表。功能主要包括：指标管理、公式管理、主题管理的开发以及数据分析和展示
       </p></li>
      </ul>
     </td>
    </tr>
   </tbody>
  </table>
  <h2>教育经历</h2>
  <table>
   <tbody>
    <tr>
     <th>河北理工大学</th>
	 <th>计算机科学与技术</th>
     <th> 本科 </th>
     <th> 2006.9-2010.7 </th>
    </tr>
  </tbody>
  </table>
  <h2>部分代码</h2>
  <dl>
   <dt>Storm与Kafka集成测试框架</dt>
   <dd><code><a href="https://github.com/findhy/storm-kafka" target="new">https://github.com/findhy/storm-kafka</a></code></dd>
   <dt>Titan前端可视化例子</dt>
   <dd><code><a href="https://github.com/titan-cn/titan-vivagraph" target="new">https://github.com/titan-cn/titan-vivagraph</a></code></dd>
   <dt>Mahout测试例子</dt>
   <dd><code><a href="https://github.com/findhy/mahout-example" target="new">https://github.com/findhy/mahout-example</a></code></dd>
   <dt>HBase的一个分页实现</dt>
   <dd><code><a href="https://github.com/findhy/hbase-page" target="new">https://github.com/findhy/hbase-page</a></code></dd>
  </dl>
</body>
</html>
